res <- as.data.frame(res)
# Histograma dos resíduos
ggplot(res, aes(res)) +
geom_histogram(fill = 'blue',
alpha = 0.5,
binwidth = 1)
library(ggplot2)
ggplot(res, aes(res)) +
geom_histogram(fill = 'blue',
alpha = 0.5,
binwidth = 1)
res
library(corrgram)
# Criando um corrplot
corrplot(data_cor, method = 'color')
# Criando um corrplot
corrplot(dados_completos, method = 'color')
library(corrgram)
# Criando um corrplot
corrplot(dados_completos, method = 'color')
library(corrplot)
# Criando um corrplot
corrplot(dados_completos, method = 'color')
# Criando um corrplot
corrplot(dados_numericos, method = 'color')
corrgram(dados_numericos)
# Criando um corrplot
corrplot(dados_numericos, method = 'color')
# Criando um corrplot
corrplot(dados_numerico)
# Criando um corrplot
corrplot(dados_numericos)
# Criando um corrplot
corrplot(dados_numericos, is.corr = FALSE,method = "color")
# Criando um corrplot
correlacao <- cor(dados_numericos)
corrplot(correlacao,method = "color")
corrgram(dados_numericos)
corrgram(dados_numericos, order = TRUE, lower.panel = panel.shade,
upper.panel = panel.pie, text.panel = panel.txt)
table(dados_numericos$Media_Consumo)
# Preprando o plot
require(lattice)
#Visualizar matriz de correlação
# Criando um corrplot
correlacao <- cor(dados_numericos)
plot.cors <- function(x, labs){
diag(x) <- 0.0
plot( levelplot(x,
main = paste("Plot de Correlação usando Método", labs),
scales = list(x = list(rot = 90), cex = 1.0)) )
}
modelo <- randomForest( Media_Consumo ~ .
data = dados_numericos,
modelo <- randomForest( Media_Consumo ~ .,
data = dados_numericos,
ntree = 100, nodesize = 10, importance = T)
library(randomForest)
modelo <- randomForest( Media_Consumo ~ .,
data = dados_numericos,
ntree = 100, nodesize = 10, importance = T)
# Plotando as variáveis por grau de importância
varImpPlot(modelo) # pontos mais à direita informam as variáveis mais importantes
#Gerando o promeiro Modelo
modelo <- lm(Media_Consumo ~ ., data =treino)
summary(modelo)
plot(correlacao)
# Visualizando os valores previstos e observados
resultados <- cbind(previsto, teste$Media_Consumo)
colnames(resultados) <- c('Previsto','Real')
resultados <- as.data.frame(resultados)
resultados
min(resultados)
# Calculando o erro médio
# Quão distantes seus valores previstos estão dos valores observados
# MSE
mse <- mean((resultados$Real - resultados$Previsto)^2)
print(mse)
# Calculando o erro médio
# Quão distantes seus valores previstos estão dos valores observados
# MSE
mse <- mean((resultados$Real - resultados$Previsto)^2)
print(mse)
# RMSE
rmse <- mse^0.5
rmse
# Calculando R Squared
SSE = sum((resultados$Previsto - resultados$Real)^2)
SST = sum((mean(df$G3) - resultados$Real)^2)
# R-Squared
# Ajuda a avaliar o nível de precisão do nosso modelo. Quanto maior, melhor, sendo 1 o valor ideal.
R2 = 1 - (SSE/SST)
SST = sum((mean(dados_numericos$Media_Consumo) - resultados$Real)^2)
# R-Squared
# Ajuda a avaliar o nível de precisão do nosso modelo. Quanto maior, melhor, sendo 1 o valor ideal.
R2 = 1 - (SSE/SST)
R2
rmse
# Calculando o erro médio
# Quão distantes seus valores previstos estão dos valores observados
# MSE
mse <- mean((resultados$Real - resultados$Previsto)^2)
print(mse)
# RMSE
rmse <- mse^0.5
rmse
# Calculando o erro médio
# Quão distantes seus valores previstos estão dos valores observados
# Calculando o Mean Squared Error
MSE <- sum((teste$Media_Consumo - previsto)^2)/nrow(teste)
MSE
summary(modelo)
setwd("D:/Envios git/Projetos R/Projetos Carros Elétricos")
getwd()
library(readxl)
library(caTools)
library(randomForest)
library(ggplot2)
library(corrgram)
library(corrplot)
# Carrega o dataset
dados <- read_excel("FEV-data-Excel.xlsx")
#Visualiza informações do dataset
View(dados)
str(dados)
summary(dados)
sum(is.na(dados))
dados[sapply(dados, is.character)] <- lapply(dados[sapply(dados, is.character)], as.factor)
#ajustar nomes das colunas
names(dados) <- c("Carro", "Marca", "Modelo","Preco_Minimo","Potencia","Torque","Freios",
"Tracao","Capacidade_Bateria","Alcance_WLTP", "Distancia_Eentre_Eixos",
"Comprimento", "Largura", "Altura","Peso_Vazio_Minimo", "Peso_Admissivel",
"Capacidade_Carga", "Assentos", "Portas", "Aro", "Velocidade_Maxima",
"Porta_Malas_Litros", "Aceleracao_0_100", "Potencia_Carregamento", "Media_Consumo")
#verificar o dado com NA
dados[!complete.cases(dados),]
sum(complete.cases(dados))
#Criar dataframe com dados completos
dados_completos <- dados[complete.cases(dados),]
View(dados_completos)
#Criar dataframe com dados incompletos
dados_incompletos <- dados[!complete.cases(dados),]
View(dados_incompletos)
#boxplot por variável
nomes <- names(dados_completos)
for(i in seq_along(dados_completos)){
if(is.numeric(dados_completos[,i])){
boxplot(dados_completos[,i], main = nomes[i])
}
}
#remove nomes e o iterador da memoria
rm(nomes, i)
#---------------------------
#Modelos com dados completos
#---------------------------
#selecionando as variaveis numericas
dados_numericos <- dados_completos[sapply(dados, is.numeric)]
View(dados_numericos)
#Visualizar matriz de correlação
# Criando um corrplot
correlacao <- cor(dados_numericos)
corrplot(correlacao,method = "color")
corrgram(dados_numericos)
#Split de dados
?sample.split
amostra <- sample.split(dados_numericos$Media_Consumo, SplitRatio = 0.80)
# Criando dados de treino - 80% dos dados
treino = subset(dados_numericos, amostra == TRUE)
# Criando dados de teste - 20% dos dados
teste = subset(dados_numericos, amostra == FALSE)
#remove amostra da memória
rm(amostra)
# Avalidando a importância de todas as variaveis
modelo <- randomForest( Media_Consumo ~ .,
data = dados_numericos,
ntree = 100, nodesize = 10, importance = T)
# Plotando as variáveis por grau de importância
varImpPlot(modelo)
#Gerando o promeiro Modelo
modelo <- lm(Media_Consumo ~ ., data =treino)
summary(modelo)
#R square de 0,93, isso significa ser um bom modelo
# Obtendo os resíduos
res <- residuals(modelo)
# Convertendo o objeto para um dataframe
res <- as.data.frame(res)
res
# Histograma dos resíduos
ggplot(res, aes(res)) +
geom_histogram(fill = 'blue',
alpha = 0.5,
binwidth = 1)
#realizando os testes
previsto = predict(modelo,newdata = teste)
# Visualizando os valores previstos e observados
resultados <- cbind(previsto, teste$Media_Consumo)
colnames(resultados) <- c('Previsto','Real')
resultados <- as.data.frame(resultados)
resultados
min(resultados)
# Calculando o erro médio
# Quão distantes seus valores previstos estão dos valores observados
# MSE
mse <- mean((resultados$Real - resultados$Previsto)^2)
mse
setwd("D:/Envios git/Projetos R/Projetos Carros Elétricos")
getwd()
library(readxl)
library(caTools)
library(randomForest)
library(ggplot2)
library(corrgram)
library(corrplot)
# Carrega o dataset
dados <- read_excel("FEV-data-Excel.xlsx")
#Visualiza informações do dataset
View(dados)
str(dados)
summary(dados)
sum(is.na(dados))
dados[sapply(dados, is.character)] <- lapply(dados[sapply(dados, is.character)], as.factor)
#ajustar nomes das colunas
names(dados) <- c("Carro", "Marca", "Modelo","Preco_Minimo","Potencia","Torque","Freios",
"Tracao","Capacidade_Bateria","Alcance_WLTP", "Distancia_Eentre_Eixos",
"Comprimento", "Largura", "Altura","Peso_Vazio_Minimo", "Peso_Admissivel",
"Capacidade_Carga", "Assentos", "Portas", "Aro", "Velocidade_Maxima",
"Porta_Malas_Litros", "Aceleracao_0_100", "Potencia_Carregamento", "Media_Consumo")
#verificar o dado com NA
dados[!complete.cases(dados),]
sum(complete.cases(dados))
#Criar dataframe com dados completos
dados_completos <- dados[complete.cases(dados),]
View(dados_completos)
#Criar dataframe com dados incompletos
dados_incompletos <- dados[!complete.cases(dados),]
View(dados_incompletos)
#boxplot por variável
nomes <- names(dados_completos)
for(i in seq_along(dados_completos)){
if(is.numeric(dados_completos[,i])){
boxplot(dados_completos[,i], main = nomes[i])
}
}
#remove nomes e o iterador da memoria
rm(nomes, i)
#---------------------------
#Modelos com dados completos
#---------------------------
#selecionando as variaveis numericas
dados_numericos <- dados_completos[sapply(dados, is.numeric)]
View(dados_numericos)
#Visualizar matriz de correlação
# Criando um corrplot
correlacao <- cor(dados_numericos)
corrplot(correlacao,method = "color")
corrgram(dados_numericos)
#Split de dados
?sample.split
amostra <- sample.split(dados_numericos$Media_Consumo, SplitRatio = 0.80)
# Criando dados de treino - 80% dos dados
treino = subset(dados_numericos, amostra == TRUE)
# Criando dados de teste - 20% dos dados
teste = subset(dados_numericos, amostra == FALSE)
#remove amostra da memória
rm(amostra)
# Avalidando a importância de todas as variaveis
modelo <- randomForest( Media_Consumo ~ .,
data = dados_numericos,
ntree = 100, nodesize = 10, importance = T)
# Plotando as variáveis por grau de importância
varImpPlot(modelo)
#Gerando o promeiro Modelo
modelo <- lm(Media_Consumo ~ ., data =treino)
summary(modelo)
#R square de 0,93, isso significa ser um bom modelo
# Obtendo os resíduos
res <- residuals(modelo)
# Convertendo o objeto para um dataframe
res <- as.data.frame(res)
res
# Histograma dos resíduos
ggplot(res, aes(res)) +
geom_histogram(fill = 'blue',
alpha = 0.5,
binwidth = 1)
#realizando os testes
previsto = predict(modelo,newdata = teste)
# Visualizando os valores previstos e observados
resultados <- cbind(previsto, teste$Media_Consumo)
colnames(resultados) <- c('Previsto','Real')
resultados <- as.data.frame(resultados)
resultados
min(resultados)
# Calculando o erro médio
# Quão distantes seus valores previstos estão dos valores observados
# MSE
mse <- mean((resultados$Real - resultados$Previsto)^2)
mse
#remove as correlações
rm(correlacao)
# Obtendo os resíduos
residuals(modelo)
#removendo os residuos
rm(res)
#removendo o RMSE e o dataframe resultados
rm(mse, resultados)
#Criando o segundo modelo
modelo_2 <- randomForest( Media_Consumo ~ .,
data = dados_numericos,
ntree = 100, nodesize = 10)
summary(modelo_2)
#realizando os testes
previsto = predict(modelo_2,newdata = teste)
# Visualizando os valores previstos e observados
resultados <- cbind(previsto, teste$Media_Consumo)
colnames(resultados) <- c('Previsto','Real')
resultados <- as.data.frame(resultados)
resultados
# Calculando o erro médio
# Quão distantes seus valores previstos estão dos valores observados
# MSE
mse <- mean((resultados$Real - resultados$Previsto)^2)
mse
#removendo o MSE e o dataframe resultados
rm(mse, resultados)
maximos <- apply(dados_completos,MARGIN = 2, max)
maximos
minimos <- apply(dados_completos,MARGIN = 2, min)
minimos
maximos <- apply(dados_numericos,MARGIN = 2, max)
maximos
minimos <- apply(dados_numericos,MARGIN = 2, min)
minimos
#normalização min max
dados_normalizados <-  as.data.frame(scale(dados_numericos, center = minimos, scale = maximos - minimos))
# Criando novos dados de treino - 80% dos dados
treino_2 = subset(dados_normalizados, amostra == TRUE)
# Criando as amostras de forma randômica
amostra <- sample.split(dados_normalizados$medv, SplitRatio = 0.80)
# Criando as amostras de forma randômica
amostra <- sample.split(dados_normalizados$Media_Consumo, SplitRatio = 0.80)
# Criando novos dados de treino - 80% dos dados
treino_2 = subset(dados_normalizados, amostra == TRUE)
# Criando novos dados de teste - 20% dos dados
teste_2 = subset(dados_normalizados, amostra == FALSE)
#remove a variavel amostra
rm(amostra)
#treinando o modelo
modelo_neural <- neuralnet(Media_Consumo ~ ., treino, hidden=c(5,3), linear.output = T)
library(neuralnet)
#treinando o modelo
modelo_neural <- neuralnet(Media_Consumo ~ ., treino, hidden=c(5,3), linear.output = T)
summary(modelo_neural)
plot(modelo_neural)
previsto <- predict(modelo_neural, teste)
# Convertendo os dados de teste para a escala original
previsoes <- previsto * (max(dados_normalizados$Media_Consumo) - min(dados_normalizados$Media_Consumo)) + min(dados_normalizados$Media_Consumo)
# Convertendo os dados de teste para a escala original
previsoes <- previsto * (max(dados_numericos$Media_Consumo) - min(dados_numericos$Media_Consumo)) + min(dados_numericos$Media_Consumo)
teste_convertido <- (teste$Media_Consumo) * (max(dados_numericos$Media_Consumo) - min(dados_numericos$Media_Consumo)) + min(dados_numericos$Media_Consumo)
teste_convertido
previsoes
#normalização min max
dados_normalizados <-  as.data.frame(scale(dados_numericos, center = minimos, scale = maximos - minimos))
View(dados_normalizados)
# Criando as amostras de forma randômica
amostra <- sample.split(dados_normalizados$Media_Consumo, SplitRatio = 0.80)
# Criando novos dados de treino - 80% dos dados
treino_2 = subset(dados_normalizados, amostra == TRUE)
# Criando novos dados de teste - 20% dos dados
teste_2 = subset(dados_normalizados, amostra == FALSE)
#remove a variavel amostra
rm(amostra)
View(teste_2)
View(treino_2)
#treinando o modelo
modelo_neural <- neuralnet(Media_Consumo ~ ., treino_2, hidden=c(5,3), linear.output = T)
summary(modelo_neural)
previsto <- predict(modelo_neural, teste_2)
# Convertendo os dados de teste para a escala original
previsoes <- previsto * (max(dados_numericos$Media_Consumo) - min(dados_numericos$Media_Consumo)) + min(dados_numericos$Media_Consumo)
teste_convertido <- (teste$Media_Consumo) * (max(dados_numericos$Media_Consumo) - min(dados_numericos$Media_Consumo)) + min(dados_numericos$Media_Consumo)
teste_convertido
previsoes
previsto <- predict(modelo_neural, teste_2)
previsto
teste_2$Media_Consumo
# Convertendo os dados de teste para a escala original
previsoes <- previsto * (max(dados_numericos$Media_Consumo) - min(dados_numericos$Media_Consumo)) + min(dados_numericos$Media_Consumo)
previsoes
teste_convertido <- (teste_2$Media_Consumo) * (max(dados_numericos$Media_Consumo) - min(dados_numericos$Media_Consumo)) + min(dados_numericos$Media_Consumo)
teste_convertido
#Visualizando os valores previstos e observados
resultados <- cbind(previsoes , teste_convertido)
colnames(resultados) <- c('Previsto','Real')
resultados <- as.data.frame(resultados)
resultados
# Calculando o Mean Squared Error
MSE_rede_neural <- mean((resultados$Real - resultados$Previsto)^2)
MSE_rede_neural
ggplot(resultados, aes(x = Real,y = Previsto)) +
geom_point() + stat_smooth()
# RMSE
rmse <- MSE_rede_neural^0.5
rmse
# Calculando R Squared
SSE = sum((resultados$Previsto - resultados$Real)^2)
SST = sum((mean(dados_numericos$Media_Consumo) - resultados$Real)^2)
# R-Squared
# Ajuda a avaliar o nível de precisão do nosso modelo. Quanto maior, melhor, sendo 1 o valor ideal.
R2 = 1 - (SSE/SST)
R2
#Criando o segundo modelo
modelo_2 <- randomForest( Media_Consumo ~ .,
data = dados_numericos,
ntree = 100, nodesize = 10)
summary(modelo_2)
#realizando os testes
previsto = predict(modelo_2,newdata = teste)
# Visualizando os valores previstos e observados
resultados <- cbind(previsto, teste$Media_Consumo)
colnames(resultados) <- c('Previsto','Real')
resultados <- as.data.frame(resultados)
resultados
# Calculando o erro médio
# Quão distantes seus valores previstos estão dos valores observados
# MSE
mse <- mean((resultados$Real - resultados$Previsto)^2)
mse
# RMSE
rmse <-mse^0.5
rmse
# Calculando R Squared
SSE = sum((resultados$Previsto - resultados$Real)^2)
SST = sum((mean(dados_numericos$Media_Consumo) - resultados$Real)^2)
# R-Squared
# Ajuda a avaliar o nível de precisão do nosso modelo. Quanto maior, melhor, sendo 1 o valor ideal.
R2 = 1 - (SSE/SST)
R2
#Gerando o promeiro Modelo
modelo <- lm(Media_Consumo ~ ., data =treino)
#realizando os testes
previsto = predict(modelo,newdata = teste)
# Visualizando os valores previstos e observados
resultados <- cbind(previsto, teste$Media_Consumo)
colnames(resultados) <- c('Previsto','Real')
resultados <- as.data.frame(resultados)
resultados
min(resultados)
# Calculando o erro médio
# Quão distantes seus valores previstos estão dos valores observados
# MSE
mse <- mean((resultados$Real - resultados$Previsto)^2)
mse
# RMSE
rmse <-mse^0.5
rmse
# Calculando R Squared
SSE = sum((resultados$Previsto - resultados$Real)^2)
SST = sum((mean(dados_numericos$Media_Consumo) - resultados$Real)^2)
# R-Squared
# Ajuda a avaliar o nível de precisão do nosso modelo. Quanto maior, melhor, sendo 1 o valor ideal.
R2 = 1 - (SSE/SST)
R2
modelo <- lm(Media_Consumo ~ ., data =treino)
summary(modelo)
#R square de 0,93, isso significa ser um bom modelo
# Obtendo os resíduos
res <- residuals(modelo)
# Convertendo o objeto para um dataframe
res <- as.data.frame(res)
res
# Histograma dos resíduos
ggplot(res, aes(res)) +
geom_histogram(fill = 'blue',
alpha = 0.5,
binwidth = 1)
#removendo os residuos
rm(res)
#realizando os testes
previsto = predict(modelo,newdata = teste)
# Visualizando os valores previstos e observados
resultados <- cbind(previsto, teste$Media_Consumo)
colnames(resultados) <- c('Previsto','Real')
resultados <- as.data.frame(resultados)
resultados
min(resultados)
# Calculando o erro médio
# Quão distantes seus valores previstos estão dos valores observados
# MSE
mse <- mean((resultados$Real - resultados$Previsto)^2)
mse
# RMSE
rmse <-mse^0.5
rmse
# Calculando R Squared
SSE = sum((resultados$Previsto - resultados$Real)^2)
SST = sum((mean(dados_numericos$Media_Consumo) - resultados$Real)^2)
# R-Squared
# Ajuda a avaliar o nível de precisão do nosso modelo. Quanto maior, melhor, sendo 1 o valor ideal.
R2 = 1 - (SSE/SST)
R2
#removendo os resultados
rm(mse, ,rmse, SSE,SST, R2,resultados)
#removendo os resultados
rm(mse ,rmse, SSE,SST, R2,resultados)
#removendo os resultados
rm(mse ,rmse, SSE,SST, R2,resultados)
#removendo os resultados
rm(mse ,rmse, SSE,SST, R2,resultados)
#removendo os resultados
rm(MSE_rede_neural ,rmse, SSE,SST, R2,resultados)
